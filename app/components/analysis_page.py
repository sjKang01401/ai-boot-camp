import streamlit as st
from utils.feign import start_analysis_workflow, get_survey_by_id
import json
from datetime import datetime

def show_page():
    st.title("ğŸ“Š ë™ë„¤ ë¶„ì„ ê²°ê³¼")
    st.write("""ì„ íƒëœ ì„¤ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ë™ë„¤ë¥¼ ë¶„ì„í•˜ê³  ì¶”ì²œí•©ë‹ˆë‹¤.
    """)

    selected_survey_id = st.session_state.get("selected_survey_id")

    if selected_survey_id:

        # Fetch and display selected survey details
        survey_result = get_survey_by_id(selected_survey_id)
        if survey_result["success"]:
            survey = survey_result["data"]
            if survey:
                with st.container(border=True):
                    created_at_dt = datetime.fromisoformat(survey["created_at"].replace("Z", "+00:00"))
                    formatted_created_at = created_at_dt.strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ%Më¶„")
                    
                    st.markdown(f"#### {formatted_created_at} ì„¤ë¬¸ ê²°ê³¼")
                    st.write(f"**ê°€ì¡± êµ¬ì„±:** {survey.get('family_type', 'N/A')}")
                    if survey.get('family_type_etc'):
                        st.write(f"  - ê¸°íƒ€: {survey['family_type_etc']}")
                    st.write(f"**ì—°ë ¹ëŒ€:** {survey.get('age_group', 'N/A')}")
                    st.write(f"**ì£¼ë¡œ í•˜ì‹œëŠ” ì¼:** {survey.get('job_type', 'N/A')}")
                    if survey.get('job_type_etc'):
                        st.write(f"  - ê¸°íƒ€: {survey['job_type_etc']}")
                    st.write(f"**ì£¼ê±° í˜•íƒœ:** {survey.get('housing_type', 'N/A')}")
                    if survey.get('housing_type') == 'ì „ì„¸ë¡œ ì•ˆì •ì ìœ¼ë¡œ':
                        st.write(f"**ì „ì„¸ ì˜ˆì‚°:** {survey.get('jeonse_budget', 'N/A')}")
                    elif survey.get('housing_type') == 'ë§¤ë§¤ë¡œ ë‚´ ì§‘ ë§ˆë ¨':
                        st.write(f"**ë§¤ë§¤ ì˜ˆì‚°:** {survey.get('maemae_budget', 'N/A')}")
                    st.write(f"**ì›” ì£¼ê±°ë¹„ ë¶€ë‹´:** {survey.get('monthly_cost', 'N/A')}")
                    st.write(f"**ì§ì¥/í•™êµ:** {survey.get('work_school_location', 'N/A')}")
                    st.write(f"**ìì£¼ ê°€ëŠ” ê³³:** {survey.get('frequent_location', 'N/A')}")
                    st.write(f"**ê¸°íƒ€ ëª©ì ì§€:** {survey.get('other_location', 'N/A')}")
                    st.write(f"**êµí†µìˆ˜ë‹¨:** {survey.get('transport_method', 'N/A')}")
                    st.write(f"**ì¶œí‡´ê·¼ ì‹œê°„:** {survey.get('commute_time', 'N/A')}")
                    st.write(f"**ì¤‘ìš”ë„ 1ìˆœìœ„:** {survey.get('first_priority', 'N/A')}")
                    st.write(f"**ì¤‘ìš”ë„ 2ìˆœìœ„:** {survey.get('second_priority', 'N/A')}")
                    st.write(f"**ì¤‘ìš”ë„ 3ìˆœìœ„:** {survey.get('third_priority', 'N/A')}")
                    st.write(f"**ì§‘ì—ì„œ ì£¼ë¡œ í•˜ëŠ” ì¼:** {survey.get('home_activity', 'N/A')}")
                    st.write(f"**ì£¼ë§ì— ì£¼ë¡œ í•˜ëŠ” ì¼:** {survey.get('weekend_activity', 'N/A')}")
                    st.write(f"**ì†ŒìŒ ë¯¼ê°ë„:** {survey.get('noise_sensitivity', 'N/A')}")
                    st.write(f"**ê¼­ í”¼í•˜ê³  ì‹¶ì€ ê²ƒ:** {survey.get('avoid_item', 'N/A')}")
                    if survey.get('avoid_item_etc'):
                        st.write(f"  - ê¸°íƒ€: {survey['avoid_item_etc']}")
                    st.write(f"**ê¼­ ìˆì—ˆìœ¼ë©´ í•˜ëŠ” ê²ƒ:** {survey.get('want_item', 'N/A')}")
                    if survey.get('want_item_etc'):
                        st.write(f"  - ê¸°íƒ€: {survey['want_item_etc']}")
                    st.write(f"**ì¶”ê°€ ì˜ê²¬:** {survey.get('additional_comments', 'N/A')}")
            else:
                st.info("ì„ íƒëœ ì„¤ë¬¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.error(f"ì„¤ë¬¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {survey_result['message']}")
        
        if st.button("ë¶„ì„ ì‹œì‘", key="start_analysis_button"):
            with st.spinner("ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤... ì™„ë£Œê¹Œì§€ ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                                
                workflow_response = start_analysis_workflow(selected_survey_id)

                if workflow_response["success"]:
                    workflow_result = workflow_response["data"]
                    if workflow_result:
                        process_streaming_response(workflow_result)

    else:
        st.info("ì„ íƒëœ ì„¤ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ì„¤ë¬¸ í˜ì´ì§€ì—ì„œ ì„¤ë¬¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")


def _display_analysis_results(agent_type, response, docs):

    st.markdown(f"""#### {AnalysisAgentType.to_korean(agent_type)} ê²°ê³¼""")

    if isinstance(response, list):
        key_to_korean_map = {
            AnalysisAgentType.DATA_COLLECTOR: {
                'distance_to_work_school_location': 'ì§ì¥/í•™êµê¹Œì§€ ê±°ë¦¬',
                'time_to_work_school_location': 'ì§ì¥/í•™êµê¹Œì§€ ì‹œê°„',
                'distance_to_frequent_location': 'ìì£¼ ê°€ëŠ” ê³³ê¹Œì§€ ê±°ë¦¬',
                'time_to_frequent_location': 'ìì£¼ ê°€ëŠ” ê³³ê¹Œì§€ ì‹œê°„'
            },
            AnalysisAgentType.REGIONAL_ANALYZER: {
                'analysis_details': 'ë¶„ì„ ë‚´ìš©',
                'pros': 'ì¥ì ',
                'cons': 'ë‹¨ì '
            },
            AnalysisAgentType.BUDGET_OPTIMIZER: {
                'budget_suitability': 'ì˜ˆì‚° ì í•©ë„',
                'pros': 'ì¥ì ',
                'cons': 'ë‹¨ì '
            },
            AnalysisAgentType.RECOMMENDATION_SYNTHESIZER: {
                'score': 'ì¢…í•© ì ìˆ˜',
                'detailed_analysis': 'ì¢…í•© ë¶„ì„ê²°ê³¼',
                'pros': 'ì¥ì ',
                'cons': 'ë‹¨ì ',
                'recommendation_reason': 'ì¶”ì²œ ì´ìœ ',
            },
        }
        current_key_map = key_to_korean_map.get(agent_type, {})

        for i, item in enumerate(response):
            st.markdown(f"##### {i+1}. {item.get('area_name', 'N/A')}")

            markdown_text = ""
            for key, value in item.items():
                if key != 'area_name':
                    korean_key = current_key_map.get(key, key.replace('_', ' ').title())
                    if isinstance(value, list):
                        markdown_text += f"- **{korean_key}**\n"
                        for sub_item in value:
                            markdown_text += f"  - {sub_item}\n"
                    else:
                        markdown_text += f"- **{korean_key}** : {value}\n"

            st.markdown(markdown_text)

            if agent_type == AnalysisAgentType.RECOMMENDATION_SYNTHESIZER:
                if item['area_name'] in docs:
                    with st.expander(f"{item['area_name']} ìƒì„¸ ì •ë³´", expanded=False):
                        for doc_item in docs[item['area_name']]:
                            formatted_doc = doc_item.replace('\.', '\.\n')
                            st.markdown(formatted_doc)
    else:
        st.markdown(response)


def process_streaming_response(response):
    for chunk in response.iter_lines():
        if not chunk:
            continue

        # 'data: ' ì ‘ë‘ì‚¬ ì œê±°
        line = chunk.decode("utf-8")

        # lineì˜ í˜•íƒœëŠ” 'data: {"type": "update", "data": {}}'
        if not line.startswith("data: "):
            continue

        data_str = line[6:]  # 'data: ' ë¶€ë¶„ ì œê±°

        try:
            # JSON ë°ì´í„° íŒŒì‹±
            event_data = json.loads(data_str)

            # ì´ë²¤íŠ¸ ë°ì´í„° ì²˜ë¦¬
            is_complete = process_event_data(event_data)

            if is_complete:
                break

        except json.JSONDecodeError as e:
            st.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")

class AnalysisAgentType:
    DATA_COLLECTOR = "DATA_COLLECTOR"
    REGIONAL_ANALYZER = "REGIONAL_ANALYZER"
    BUDGET_OPTIMIZER = "BUDGET_OPTIMIZER"
    RECOMMENDATION_SYNTHESIZER = "RECOMMENDATION_SYNTHESIZER"

    @classmethod
    def to_korean(cls, role: str) -> str:
        if role == cls.DATA_COLLECTOR:
            return "í›„ë³´ ì§€ì—­ ìˆ˜ì§‘"
        elif role == cls.REGIONAL_ANALYZER:
            return "ì§€ì—­ ë¶„ì„"
        elif role == cls.BUDGET_OPTIMIZER:
            return "ì˜ˆì‚° ìµœì í™”"
        elif role == cls.RECOMMENDATION_SYNTHESIZER:
            return "ì¢…í•© ì¶”ì²œ"
        else:
            return role

def process_event_data(event_data):

    # ì´ë²¤íŠ¸ ì¢…ë£Œ
    if event_data.get("type") == "end":
        return True

    # ìƒˆë¡œìš´ ë©”ì„¸ì§€
    if event_data.get("type") == "update":
        # state ì¶”ì¶œ
        data = event_data.get("data", {})

        role = data.get("role")
        response = data["response"]
        docs = data.get("docs", {})

        avatar_map = {
            AnalysisAgentType.DATA_COLLECTOR: "ğŸ“Œ",
            AnalysisAgentType.REGIONAL_ANALYZER: "ğŸ—ºï¸",
            AnalysisAgentType.BUDGET_OPTIMIZER: "ğŸ’°",
            AnalysisAgentType.RECOMMENDATION_SYNTHESIZER: "ğŸ’¡",
        }
        avatar = avatar_map.get(role, "ğŸ“Š")

        with st.chat_message(AnalysisAgentType.to_korean(role), avatar=avatar):
            _display_analysis_results(role, response, docs)

    return False